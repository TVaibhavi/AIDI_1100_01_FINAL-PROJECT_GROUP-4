{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIDI_1100_01_FINAL_PROJECT_GROUP_4_update2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhsP2fCmErLx"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import datetime\n",
        "import csv\n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X94SpdEOEg95"
      },
      "source": [
        "# Constants\n",
        "News_URL = \"https://www.prnewswire.com/news-releases/news-releases-list/?\"\n",
        "#News_URL = \"https://www.prnewswire.com/news-releases/news-releases-list/?month=11&day=24&year=2021&hour=00&page=1&pagesize=100\"\n",
        "\n",
        "Total_Days = 7 #Number of days to fetch\n",
        "StockIndustry_Search = 'NYSE'\n",
        "StockSymbol_Required = 2"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoIkEyt4ExMJ"
      },
      "source": [
        "# Global Variables\n",
        "arr_Date = []\n",
        "arr_newsTitle = []\n",
        "arr_newsPara = []"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYFhYfCbE6Qg"
      },
      "source": [
        "# Date for extracting webpage\n",
        "currentDate = datetime.datetime.now()\n",
        "tempDate = currentDate"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPaKom5Ou9M6"
      },
      "source": [
        "def prepare_URL(dayToFetch) -> str:\n",
        "   urlByDay = News_URL + 'month=' + str(currentDate.month) + '&day=' + str(dayToFetch) + '&year=' + str(currentDate.year) + '&hour=00&page=1&pagesize=100'\n",
        "   return urlByDay"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzMGO92NIakg"
      },
      "source": [
        "def parse_News(forDay):\n",
        "  url = prepare_URL(forDay)\n",
        "  page = requests.get(url)\n",
        "  soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "  # to extract main layout content\n",
        "  main = soup.find_all('main',class_='headline-listing')\n",
        "\n",
        "  for elements in main:\n",
        "    lstContainer = elements.find_all('section',class_='container')\n",
        "    for mainHead in lstContainer:\n",
        "      row = mainHead.find_all('div',class_='row')\n",
        "      for mainCol in row:\n",
        "        rowList = mainCol.find_all('div',class_='col-md-8 col-sm-8 card-list card-list-hr')\n",
        "        for newsCard in rowList:\n",
        "          newsLst = newsCard.find_all('a',class_='newsreleaseconsolidatelink')\n",
        "          for content in newsLst:\n",
        "            small = content.h3.small.text\n",
        "            content.h3.small.decompose()\n",
        "            h3 = content.h3.text.replace(\"\\n\", \"\")\n",
        "            p =  content.p.text\n",
        "            arr_Date.append(small)\n",
        "            arr_newsTitle.append(h3)\n",
        "            arr_newsPara.append(p)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P65CV6KnOCIe"
      },
      "source": [
        "#Fetch & Parse data of last week\n",
        "i = 0\n",
        "while i < Total_Days:\n",
        "  parse_News(currentDate.day - i)\n",
        "  i = i + 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pURL0S_bEMe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0fafb123-c9ec-468f-db58-a6c5eb00adc2"
      },
      "source": [
        "# Write data to csv\n",
        "dictNews = {'Date': arr_Date, 'Title': arr_newsTitle, 'Content': arr_newsPara}\n",
        "df = pd.DataFrame(dictNews)\n",
        "df.to_csv('newsData.csv')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23:19 ET</td>\n",
              "      <td>SHAREHOLDER ALERT: Pomerantz Law Firm Reminds ...</td>\n",
              "      <td>Pomerantz LLP announces that a class action la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23:19 ET</td>\n",
              "      <td>SHAREHOLDER ALERT: Pomerantz Law Firm Investig...</td>\n",
              "      <td>Pomerantz LLP is investigating claims on behal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23:17 ET</td>\n",
              "      <td>SHAREHOLDER ALERT: Pomerantz Law Firm Reminds ...</td>\n",
              "      <td>Pomerantz LLP announces that a class action la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23:16 ET</td>\n",
              "      <td>SHAREHOLDER ALERT: Pomerantz Law Firm Investig...</td>\n",
              "      <td>Pomerantz LLP is investigating claims on behal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23:15 ET</td>\n",
              "      <td>SHAREHOLDER ALERT: Pomerantz Law Firm Investig...</td>\n",
              "      <td>Pomerantz LLP is investigating claims on behal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date  ...                                            Content\n",
              "0  23:19 ET  ...  Pomerantz LLP announces that a class action la...\n",
              "1  23:19 ET  ...  Pomerantz LLP is investigating claims on behal...\n",
              "2  23:17 ET  ...  Pomerantz LLP announces that a class action la...\n",
              "3  23:16 ET  ...  Pomerantz LLP is investigating claims on behal...\n",
              "4  23:15 ET  ...  Pomerantz LLP is investigating claims on behal...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2h3XKOdXAtQ"
      },
      "source": [
        "#Search stock symbols of given industry\n",
        "\n",
        "searchString = StockIndustry_Search + ': ([a-zA-Z]+)'\n",
        "df_stockSymbols = df['Content'].str.extract(searchString, expand=True)\n",
        "\n",
        "# Dropping the duplicates \n",
        "df_stockSymbols = df_stockSymbols.drop_duplicates()\n",
        "\n",
        "# Dropping the missing values.\n",
        "df_stockSymbols = df_stockSymbols.dropna() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAjI7G8_p8OV"
      },
      "source": [
        "#Yahoo Finance API\n"
      ]
    }
  ]
}